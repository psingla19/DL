Aim12: Write a program to generate MNIST Digits using GANs


# Import Libraries
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import matplotlib.pyplot as plt
from IPython import display

# Set display format for matplotlib
display.set_matplotlib_formats('svg')
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')



# Load and Normalize Data
data = np.loadtxt(open('sample_data/mnist_train_small.csv', 'rb'), delimiter=',')
data = data[:, 1:]  # Remove labels
data = 2 * (data / np.max(data)) - 1  # Normalize to range [-1, 1]
dataT = torch.tensor(data).float()  # Convert to tensor

# Set Parameters
batch_size = 100  # Define batch size for training

# Define Discriminator Network
class DiscriminatorNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 256)
        self.fc2 = nn.Linear(256, 256)
        self.out = nn.Linear(256, 1)

    def forward(self, x):
        x = F.leaky_relu(self.fc1(x))
        x = F.leaky_relu(self.fc2(x))
        x = self.out(x)
        return torch.sigmoid(x)

dnet = DiscriminatorNet()
y = dnet(torch.randn(10,784))

# Define Generator Network
class GeneratorNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(64, 256)
        self.fc2 = nn.Linear(256, 256)
        self.out = nn.Linear(256, 784)

    def forward(self, x):
        x = F.leaky_relu(self.fc1(x))
        x = F.leaky_relu(self.fc2(x))
        x = self.out(x)
        return torch.tanh(x)

gnet = GeneratorNet().to(device)
y = gnet(torch.randn(10,64))
plt.imshow(y[0,:].detach().squeeze().view(28,28));





# Loss Function and Optimizers
loss_fn = nn.BCELoss()

# Initialize Networks
dnet = DiscriminatorNet().to(device)
gnet = GeneratorNet().to(device)

d_optimizer = torch.optim.Adam(dnet.parameters(), lr=0.0003)
g_optimizer = torch.optim.Adam(gnet.parameters(), lr=0.0003)

# Training Loop
num_epochs = 50000
losses = np.zeros((num_epochs, 2))
discriminator_decisions = np.zeros((num_epochs, 2))

for epoch in range(num_epochs):
    # Create minibatches of real and fake images
    rand_idx = torch.randint(dataT.shape[0], (batch_size,))
    real_images = dataT[rand_idx, :].to(device)
    fake_images = gnet(torch.randn(batch_size, 64).to(device))

    # Labels for real and fake images
    real_labels = torch.ones(batch_size, 1).to(device)
    fake_labels = torch.zeros(batch_size, 1).to(device)

    # Train Discriminator
    pred_real = dnet(real_images)
    d_loss_real = loss_fn(pred_real, real_labels)

    pred_fake = dnet(fake_images.detach())
    d_loss_fake = loss_fn(pred_fake, fake_labels)

    d_loss = d_loss_real + d_loss_fake
    losses[epoch, 0] = d_loss.item()
    discriminator_decisions[epoch, 0] = torch.mean((pred_real > 0.5).float()).detach()
    discriminator_decisions[epoch, 1] = torch.mean((pred_fake > 0.5).float()).detach()

    d_optimizer.zero_grad()
    d_loss.backward()
    d_optimizer.step()

    # Train Generator
    fake_images = gnet(torch.randn(batch_size, 64).to(device))
    pred_fake = dnet(fake_images)
    g_loss = loss_fn(pred_fake, real_labels)

    losses[epoch, 1] = g_loss.item()
    g_optimizer.zero_grad()
    g_loss.backward()
    g_optimizer.step()


# Print Status
    if epoch % 5000 == 0:
        print(f'Epoch [{epoch}/{num_epochs}] - Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}')

# Plot Losses
fig, ax = plt.subplots(1, 2, figsize=(10, 4))
ax[0].plot(losses, label=['Discriminator', 'Generator'])
ax[0].set_title('Model Loss')
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Loss')
ax[0].legend()

ax[1].plot(discriminator_decisions, label=['Real', 'Fake'])
ax[1].set_title('Discriminator Accuracy')
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Accuracy')
ax[1].legend()
plt.show()





# Generate and Display Fake Images
gnet.eval()
fake_data = gnet(torch.randn(12, 64).to(device)).cpu()

fig, axs = plt.subplots(3, 4, figsize=(8, 6))
for ax, img in zip(axs.flatten(), fake_data):
    ax.imshow(img.data.squeeze().detach().view(28, 28), cmap='gray')
    ax.axis('off')
plt.show()
